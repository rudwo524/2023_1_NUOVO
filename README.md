# 2023_1_NUOVO

## 03-2 선형 회귀(Linear Regression)

### k-최근접 이웃의 한계

#### 3.1절에서 50cm의 농어를 1033g 정도로 예측하였는데, 실제로는 더 나간다.
#### k-neighbors 를 사용하면 가장 가까운 이웃까지의 거리와 이웃 샘플의 인덱스를 얻을 수 있다.
#### 길이가 50cm이고 무게가 1033g인 농어는 세모(marker='^')로 표시, 주변의 샘플은 다이아몬드로 표시 (marker = 'D')
#### 농어의 길이와 무게가 비례하는경향이 있는데, 50cm의 농어에서 k-근접을 사용하면 
#### 가장 가까운 근방인 45cm인 샘플들의 평균을 계산해서 예측하기 때문에 50cm 농어의 실제 무게보다 예측값이 더 작게 된다.
#### 여기서 문제점 -> 농어의 길이가 아무리 커져도 k-근접을 사용하면 무게가 더 증가하지 않는 방향으로 예측된다
#### k-neareat를 사용하여 이 문제를 해결하려면 가장 길이가 큰 농어가 포함되도록 training set을 다시 만들어야 하므로 불편하다.
#### 이런 한계점을 극복하기 위해서 해결 방안으로 제시된 것이 바로 선형 회귀이다.

### 선형 회귀(Linear Regression)

#### 이름에서 알 수 있듯이 특성이 하나인 경우 직선을 학습하는 algorithm이다.
#### 사이킷런은 sklearn.linear_model 패키지 아래에 LinearRegression 클래스를 만들어 놓았는데, 이 클래스에는 
#### 1.fit()
#### 2.score()
#### 3.predict()
#### 메서드가 존재한다.
#### linear regression 모델을 사용했을 때 이 모델은 50cm의 농어의 무게를 1240cm정도로 아주 높게 예측했는데,
#### linear regression에서 찾은 직선을 y=ax+b(x를 농어의 길이, y를 농어의 무게)라고 하면
#### a는 대략 39, b는 대략 -709가 나오는데
#### x=15, x=50 일 때의 두 점을 연결하면 직선을 구할 수가 있다.
#### 따라서 이를 사용하면 훈련 세트 범위를 벗어난 농어의 무게도 예측할 수가 있게 되는 것이므로 k-nearest보다 더 좋은 알고리즘이라고 할 수가 있다.
#### 하지만 이 또한 training set과 test set에서 오차가 조금 있는데
#### 이를 극복하기 위해 다음 절에서는 다항 회귀에 대해 공부해 보겠다.

### 다항 회귀

####
